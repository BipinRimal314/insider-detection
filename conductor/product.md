# Product Guide: Insider Threat Detection System

## Initial Concept
Unsupervised Behavioral Profiling for Insider Threat Detection Using Time-Series and Anomaly Detection Techniques.

## 1. Target Users
- **Security Operations Center (SOC) Analysts**: The primary users who will investigate alerts generated by the system. The system aims to reduce their workload by filtering noise and prioritizing high-risk anomalies.
- **Data Scientists/Researchers**: Users interested in the underlying machine learning models, experimental results, and extending the research (e.g., testing new models or datasets).

## 2. Core Goals
- **Unsupervised Detection**: Detect malicious insider activity without relying on labeled training data, addressing the challenge of scarce ground truth in real-world scenarios.
- **Temporal Behavioral Analysis**: Leverage deep learning, specifically LSTM Autoencoders, to model and detect deviations in user behavior sequences over time.
- **Explainable Security**: Provide interpretable alerts and visualizations (e.g., contribution of specific features to an anomaly score) to aid SOC analysts in their investigations.

## 3. Technical Constraints & Requirements
- **Scalability**: The system must be capable of processing large-scale log datasets (e.g., CMU-CERT dataset with 100M+ events) efficiently.
- **Low Latency**: The architecture should support near real-time detection capabilities to identify threats as they occur.
- **Forensic Interpretability**: The system must output clear evidence and context for detected anomalies to facilitate forensic auditing and compliance.
- **Resource Constraints**: The solution should be deployable on constrained hardware environments (e.g., standard servers with limited RAM/CPU), necessitating efficient model design (e.g., "flash" models).
